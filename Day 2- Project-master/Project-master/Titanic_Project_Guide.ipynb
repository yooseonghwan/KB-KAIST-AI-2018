{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 본 프로젝트에 사용할 라이브러리입니다.\n",
    "# 이후 셀을 실행하기 이전에 먼저 실행되어야 합니다.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data analysis\n",
    "$\\quad$Preprocessing, Machine Learning 알고리즘 적용에 앞서 먼저 주어진 데이터가 어떻게 구성되어 있는지 파악하는 것이 중요합니다. 본 Kaggle Project에서 제시한 데이터는 다음과 같은 정보를 포함하고 있습니다.\n",
    "<br>\n",
    "<img src=\"img/info.png\">\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$위와 같은 정보가 어떤 식으로 데이터에 저장되어 있는지, 그리고 데이터의 분포나 특징은 어떠한지 아래 설명과 코드를 통해 알아보도록 합시다.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  데이터 읽어오기\n",
    "train_data = pd.read_csv('data/train.csv');\n",
    "test_data = pd.read_csv('data/test.csv');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$먼저, 데이터를 읽어오는 부분입니다. 데이터는 training을 위한 train.csv와 test를 위한 test.csv가 있습니다. 두 데이터를 읽어오기 위해 pandas 라이브러리의 read_csv 함수를 이용합니다. 불러온 데이터는 각각 train_data와 test_data로 지정됩니다. \n",
    "<br>\n",
    "\n",
    "$\\quad$읽어온 데이터에 위 정보들이 어떤 식으로 저장되어 있는지 확인해 볼 필요가 있습니다. 아래 코드를 실행시켜 train.csv와 test.csv의 일부를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data 중 처음 5개만 열기\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.tail of      PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "5              6         0       3   \n",
       "6              7         0       1   \n",
       "7              8         0       3   \n",
       "8              9         1       3   \n",
       "9             10         1       2   \n",
       "10            11         1       3   \n",
       "11            12         1       1   \n",
       "12            13         0       3   \n",
       "13            14         0       3   \n",
       "14            15         0       3   \n",
       "15            16         1       2   \n",
       "16            17         0       3   \n",
       "17            18         1       2   \n",
       "18            19         0       3   \n",
       "19            20         1       3   \n",
       "20            21         0       2   \n",
       "21            22         1       2   \n",
       "22            23         1       3   \n",
       "23            24         1       1   \n",
       "24            25         0       3   \n",
       "25            26         1       3   \n",
       "26            27         0       3   \n",
       "27            28         0       1   \n",
       "28            29         1       3   \n",
       "29            30         0       3   \n",
       "..           ...       ...     ...   \n",
       "861          862         0       2   \n",
       "862          863         1       1   \n",
       "863          864         0       3   \n",
       "864          865         0       2   \n",
       "865          866         1       2   \n",
       "866          867         1       2   \n",
       "867          868         0       1   \n",
       "868          869         0       3   \n",
       "869          870         1       3   \n",
       "870          871         0       3   \n",
       "871          872         1       1   \n",
       "872          873         0       1   \n",
       "873          874         0       3   \n",
       "874          875         1       2   \n",
       "875          876         1       3   \n",
       "876          877         0       3   \n",
       "877          878         0       3   \n",
       "878          879         0       3   \n",
       "879          880         1       1   \n",
       "880          881         1       2   \n",
       "881          882         0       3   \n",
       "882          883         0       3   \n",
       "883          884         0       2   \n",
       "884          885         0       3   \n",
       "885          886         0       3   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                     Moran, Mr. James    male   NaN      0   \n",
       "6                              McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                       Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                      Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                         Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14                Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "15                    Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
       "16                                Rice, Master. Eugene    male   2.0      4   \n",
       "17                        Williams, Mr. Charles Eugene    male   NaN      0   \n",
       "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
       "19                             Masselmani, Mrs. Fatima  female   NaN      0   \n",
       "20                                Fynney, Mr. Joseph J    male  35.0      0   \n",
       "21                               Beesley, Mr. Lawrence    male  34.0      0   \n",
       "22                         McGowan, Miss. Anna \"Annie\"  female  15.0      0   \n",
       "23                        Sloper, Mr. William Thompson    male  28.0      0   \n",
       "24                       Palsson, Miss. Torborg Danira  female   8.0      3   \n",
       "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0      1   \n",
       "26                             Emir, Mr. Farred Chehab    male   NaN      0   \n",
       "27                      Fortune, Mr. Charles Alexander    male  19.0      3   \n",
       "28                       O'Dwyer, Miss. Ellen \"Nellie\"  female   NaN      0   \n",
       "29                                 Todoroff, Mr. Lalio    male   NaN      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "861                        Giles, Mr. Frederick Edward    male  21.0      1   \n",
       "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.0      0   \n",
       "863                  Sage, Miss. Dorothy Edith \"Dolly\"  female   NaN      8   \n",
       "864                             Gill, Mr. John William    male  24.0      0   \n",
       "865                           Bystrom, Mrs. (Karolina)  female  42.0      0   \n",
       "866                       Duran y More, Miss. Asuncion  female  27.0      1   \n",
       "867               Roebling, Mr. Washington Augustus II    male  31.0      0   \n",
       "868                        van Melkebeke, Mr. Philemon    male   NaN      0   \n",
       "869                    Johnson, Master. Harold Theodor    male   4.0      1   \n",
       "870                                  Balkic, Mr. Cerin    male  26.0      0   \n",
       "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n",
       "872                           Carlsson, Mr. Frans Olof    male  33.0      0   \n",
       "873                        Vander Cruyssen, Mr. Victor    male  47.0      0   \n",
       "874              Abelson, Mrs. Samuel (Hannah Wizosky)  female  28.0      1   \n",
       "875                   Najib, Miss. Adele Kiamie \"Jane\"  female  15.0      0   \n",
       "876                      Gustafsson, Mr. Alfred Ossian    male  20.0      0   \n",
       "877                               Petroff, Mr. Nedelio    male  19.0      0   \n",
       "878                                 Laleff, Mr. Kristo    male   NaN      0   \n",
       "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
       "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
       "881                                 Markun, Mr. Johann    male  33.0      0   \n",
       "882                       Dahlberg, Miss. Gerda Ulrika  female  22.0      0   \n",
       "883                      Banfield, Mr. Frederick James    male  28.0      0   \n",
       "884                             Sutehall, Mr. Henry Jr    male  25.0      0   \n",
       "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket      Fare        Cabin Embarked  \n",
       "0        0         A/5 21171    7.2500          NaN        S  \n",
       "1        0          PC 17599   71.2833          C85        C  \n",
       "2        0  STON/O2. 3101282    7.9250          NaN        S  \n",
       "3        0            113803   53.1000         C123        S  \n",
       "4        0            373450    8.0500          NaN        S  \n",
       "5        0            330877    8.4583          NaN        Q  \n",
       "6        0             17463   51.8625          E46        S  \n",
       "7        1            349909   21.0750          NaN        S  \n",
       "8        2            347742   11.1333          NaN        S  \n",
       "9        0            237736   30.0708          NaN        C  \n",
       "10       1           PP 9549   16.7000           G6        S  \n",
       "11       0            113783   26.5500         C103        S  \n",
       "12       0         A/5. 2151    8.0500          NaN        S  \n",
       "13       5            347082   31.2750          NaN        S  \n",
       "14       0            350406    7.8542          NaN        S  \n",
       "15       0            248706   16.0000          NaN        S  \n",
       "16       1            382652   29.1250          NaN        Q  \n",
       "17       0            244373   13.0000          NaN        S  \n",
       "18       0            345763   18.0000          NaN        S  \n",
       "19       0              2649    7.2250          NaN        C  \n",
       "20       0            239865   26.0000          NaN        S  \n",
       "21       0            248698   13.0000          D56        S  \n",
       "22       0            330923    8.0292          NaN        Q  \n",
       "23       0            113788   35.5000           A6        S  \n",
       "24       1            349909   21.0750          NaN        S  \n",
       "25       5            347077   31.3875          NaN        S  \n",
       "26       0              2631    7.2250          NaN        C  \n",
       "27       2             19950  263.0000  C23 C25 C27        S  \n",
       "28       0            330959    7.8792          NaN        Q  \n",
       "29       0            349216    7.8958          NaN        S  \n",
       "..     ...               ...       ...          ...      ...  \n",
       "861      0             28134   11.5000          NaN        S  \n",
       "862      0             17466   25.9292          D17        S  \n",
       "863      2          CA. 2343   69.5500          NaN        S  \n",
       "864      0            233866   13.0000          NaN        S  \n",
       "865      0            236852   13.0000          NaN        S  \n",
       "866      0     SC/PARIS 2149   13.8583          NaN        C  \n",
       "867      0          PC 17590   50.4958          A24        S  \n",
       "868      0            345777    9.5000          NaN        S  \n",
       "869      1            347742   11.1333          NaN        S  \n",
       "870      0            349248    7.8958          NaN        S  \n",
       "871      1             11751   52.5542          D35        S  \n",
       "872      0               695    5.0000  B51 B53 B55        S  \n",
       "873      0            345765    9.0000          NaN        S  \n",
       "874      0         P/PP 3381   24.0000          NaN        C  \n",
       "875      0              2667    7.2250          NaN        C  \n",
       "876      0              7534    9.8458          NaN        S  \n",
       "877      0            349212    7.8958          NaN        S  \n",
       "878      0            349217    7.8958          NaN        S  \n",
       "879      1             11767   83.1583          C50        C  \n",
       "880      1            230433   26.0000          NaN        S  \n",
       "881      0            349257    7.8958          NaN        S  \n",
       "882      0              7552   10.5167          NaN        S  \n",
       "883      0  C.A./SOTON 34068   10.5000          NaN        S  \n",
       "884      0   SOTON/OQ 392076    7.0500          NaN        S  \n",
       "885      5            382652   29.1250          NaN        Q  \n",
       "886      0            211536   13.0000          NaN        S  \n",
       "887      0            112053   30.0000          B42        S  \n",
       "888      2        W./C. 6607   23.4500          NaN        S  \n",
       "889      0            111369   30.0000         C148        C  \n",
       "890      0            370376    7.7500          NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # train_data 중 마지막 5개만 열기\n",
    "train_data.tail()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$train_data는 각 행에 \"PassangerId\", \"Survived\", \"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\" 정보가 포함되어 있습니다. 여기서 \"Survived\"를 제외한 11가지 정보는 feature에 해당되고 \"Survived\"는 label에 해당됩니다.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_data 중 처음 5개만 열기\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                          Name     Sex   Age  SibSp  \\\n",
       "413         1305       3            Spector, Mr. Woolf    male   NaN      0   \n",
       "414         1306       1  Oliva y Ocana, Dona. Fermina  female  39.0      0   \n",
       "415         1307       3  Saether, Mr. Simon Sivertsen    male  38.5      0   \n",
       "416         1308       3           Ware, Mr. Frederick    male   NaN      0   \n",
       "417         1309       3      Peter, Master. Michael J    male   NaN      1   \n",
       "\n",
       "     Parch              Ticket      Fare Cabin Embarked  \n",
       "413      0           A.5. 3236    8.0500   NaN        S  \n",
       "414      0            PC 17758  108.9000  C105        C  \n",
       "415      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416      0              359309    8.0500   NaN        S  \n",
       "417      1                2668   22.3583   NaN        C  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_data 중 마지막 5개만 열기\n",
    "test_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$test_data를 살펴보면 각 행에 \"PassangerId\", \"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\" 정보가 포함되어 있습니다. test_data는 모델을 검증하는 목적으로 사용하는 데이터이기 때문에 train_data와는 달리 label에 해당되는 \"Survived\" 정보가 없습니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$여기까지 살펴본 결과, \"PassangerId\"는 단순히 순서를 매기기 위해 붙여놓은 feature로 실제 생존여부 판별에는 필요 없는 데이터라는 것을 쉽게 알 수 있습니다. 그리고 \"Pclass\", \"Age\", \"SipSp\", \"Parch\", \"Fare\"는 숫자 정보로 별 다른 preprocessing을 거치지 않더라도 machine learning 알고리즘을 적용시킬수 있습니다. 하지만 그 외 \"Name\", \"Sex\", \"Ticket\", \"Cabin\", \"Embarked\"와 같이 문자 또는 문자 숫자 조합으로 이루어진 정보들은 적절한 vectorization이 필요합니다. 그 중 \"Name\", \"Ticket\", \"Cabin\"처럼 복잡한 정보는 vectorization 이전에 정보 제거 및 새로운 정보 추출 등 적절한 preprocessing이 필요하다는 것을 확인할 수 있습니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$위에서 주어진 데이터에 대해서 간단하게 파악해보았습니다. 지금부터는 주어진 데이터의 분포, 생존 여부(\"Survived\")와의 연광성 등을 살펴보고 어떻게 preprocessing을 하면 좋을지 생각해보겠습니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$먼저 데이터 중 숫자로 이루어진 정보들의 분포를 확인해보겠습니다. 분포를 확인하기 위해 아래 코드를 실행시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data의 숫자 정보 분석\n",
    "train_data.describe(percentiles=[0.25, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$위 코드 결과 train_data에서 숫자 정보들의 count(개수), mean(평균), std(표준편차), min(최솟값), 정보를 오름차순으로 나열했을 때 상위 25%, 50%, 75%에 해당하는 값, max(최댓값)들이 출력됩니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$먼저 count정보를 확인해보겠습니다. 단순히 순서를 매긴 \"PassengerId\"의 갯수가 891인 것으로 보아 train_data에는 총 891명의 정보가 포함되어 있음을 확인할 수 있습니다. 그리고 \"Age\"의 count가 714인 것으로 보아 177명은 \"Age\"가 알려져 있지 않다는 것을 확인할 수 있습니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$다음으로 mean입니다. mean을 통해 탑승객의 탑승객의 생존율(38.4%), 티켓 등급(2.3등급), 평균 나이(29.7세), 평균 자매 수(0.52명), 평균 부모 자녀 수(0.38명), 평균 티켓 비용(32.2)을 확인할 수 있습니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$다음으로는 min, max, 25%, 50%, 75%에 해당하는 값입니다. 이 값을 통해 전반적인 분포를 파악할 수 있고 다양한 해석이 가능합니다. 예를 들면, \"SibSp\", \"Parch\"는 상위 75%까지도 1또는 0이므로 대부분의 탑승객이 가족 없이 혼자 탑승했음을 유추할 수 있습니다. 그리고 \"Fare\"의 75%까지는 31이었지만 max가 512인 것으로 보아 일부 고객들은 다른 고객들과는 차원이 다른 금액을 지불하고 탑승했음을 확인할 수 있습니다. 이 외에 상위 60% 또는 80% 등에 해당하는 값을 확인하고 싶으시면 위 코드의 percentile 내부의 값을 0.75, 0.8로 수정하면 됩니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$숫자로 이루어진 정보를 제외한 다른 정보들의 분포는 다음 코드를 실행시켜 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Smith, Miss. Marion Elsie</td>\n",
       "      <td>male</td>\n",
       "      <td>347082</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name   Sex  Ticket    Cabin Embarked\n",
       "count                         891   891     891      204      889\n",
       "unique                        891     2     681      147        3\n",
       "top     Smith, Miss. Marion Elsie  male  347082  B96 B98        S\n",
       "freq                            1   577       7        4      644"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data의 숫자 외 정보 분석\n",
    "train_data.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$위 코드 결과 숫자 외 정보인 \"Name\", \"Sex\" ,\"Ticket\" ,\"Cabin\", \"Embarked\"의 분포가 출력됩니다. 출력 결과는 count(개수), unique(서로 다른 정보 개수), top(상위 정보), freq(가장 많이 나온 정보 개수)들이 있습니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$먼저 count부터 확인해보겠습니다. 위의 숫자 정보들에서도 확인했듯이 train_data는 총 891개로 이루어져 있기 때문에 대부분의 정보들은 891개의 값을 가지는 것을 확인할 수 있습니다. 이 때 예외로 \"Cabin\", \"Embarked\"의 정보는 알려지지 않은 부분이 있다는 것을 확인할 수 있습니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$다음으로 unique입니다. unique는 서로 다른 정보 개수입니다. Name의 경우 서로 다른 정보가 891이라는 것은 train_data의 모든 사람들이 서로 다른 이름을 가졌다는 것을 확인할 수 있습니다. 성별은 남성과 여성 두가지이므로 2라는값을 가지고, Ticket과 cabin의 경우 각각 681, 147로 같은 Ticket 또는 Cabin번호를 가진탑승객이 있다는 것을 확인할 수 있습니다. 마지막으로 Embarked는 타이타닉의 출항지가 3군데이므로 3임을 알 수 있습니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$top은 가장 많이 나온 정보이고 freq는 그 정보의 갯수를 의미합니다. \"Name\"은 각 사람마다 다 다르므로 freq가 1이고 top의 값은 큰 의미를 가지지 않습니다. \"Sex\"는 male이 577만큼 존재하므로 탑승객의 남자는 577명, 여자는  314명임을 알 수 있습니다. 그리고 \"Embarked\"를 살펴보면 탑승객의 대부분(644명)이 S(사우샘스턴)에서 탑승했음을 확인할 수 있습니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$위에서 데이터의 분포가 어떻게 되는지 살펴보았습니다. 지금부터는 이러한 분포를 가진 각 정보들이 \"Survived\"(생존여부)와 어떤 밀접한 관계를 가지는지 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived\n",
       "0       1  0.629630\n",
       "1       2  0.472826\n",
       "2       3  0.242363"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Pclass\"와 \"Survived\" 통계\n",
    "train_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 \"Pclass\"와 \"Survived\"의 관계입니다. 결과를 살펴보면 티켓 등급이 높을수록 생존율이 높은 것을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"Sex\"와 \"Survived\" 통계\n",
    "train_data[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 \"Sex\"와 \"Survived\"입니다. 여성이 남성보다 생존율이 월등히 높은 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"SibSp\"와 \"Survived\" 통계\n",
    "train_data[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"SibSp\"는 형제와 자매 수입니다. 살펴본 결과, 형제 자매 수가 적을수록 생존율이 높은 경향을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"Parch\"와 \"Survived\" 통계\n",
    "train_data[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Parch\"는 부모 자녀 수입니다. 위의 \"SibSp\"와 같이 수가 적을수록 생존율이 높은 경향을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"Embarked\"와 \"Survived\" 통계\n",
    "train_data[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Embarked\"는 탑승장소입니다. 탑승 장소가 C인 경우 생존율이 다른 지역에 비해 월등히 높으며 가장 많은 사람들이 탑승했던 S는 생존율이 가장 낮음을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$위에서 몇가지 카테고리로 분류되는 정보들을 분석해보았습니다. \"Pclass\", \"Sex\", \"Embarked\"는 \"Survived\"와 직접 연관시킬 수 있는 좋은 feature임을 확인하였습니다. \"Sex\", \"Embarked\"정보의 vectorization과 \"Embarked\"의 몇몇 알려지지 않은 정보의 복원과정 정도만 거치면 training에 사용할 수 있습니다.(물론, 다양한 preprocessing을 적용시킬 수도 있습니다.)\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$\"SibSp\"와 \"Parch\"는 위에서 살펴봤듯이 숫자가 작으면 생존율이 높다는 경향성만 있을 뿐 직접적인 연관을 찾기는 어렵습니다. 따라서 preprocessing으로 숫자가 작을 경우(4명 이하) '0'으로 클 경우(4명 초과) '1'로 분류하여 사용하는 것도 하나의 방법일 수 있습니다. 그리고 둘 다 가족의 수라는 공통점이 있으므로 굳이 이 두 가지 정보를 다 사용하는 것이 아니라 두 값을 합친 값을 \"FamilySize\"로 지정하여 사용하는 것도 좋은 preprocessing이 될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "$\\quad$Preprocessing은 머신러닝 알고리즘을 적용하기 이전에 입력 데이터를 좀 더 의미있게 만들기 위한 일련의 과정으로서 불필요한 데이터 제거, 비워진 데이터 복원, 문자 정보들의 vectorization, 각 정보로부터 새로운 정보 추출 등을 의미합니다. 본 프로젝트에서는 모든 preprocessing 방법을 허용하며, 아래 제시한 preprocessing 과정 예시 외에 여러 preprocessing과정을 생각해보고 적용시키는 것을 권장합니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$현재 주어진 데이터에 적용할 수 있는 가장 간단한 preprocessing과정은 복잡한 데이터는 제거하고 간단한 데이터만 vectorization을 시행한 후 알려지지 않은 데이터는 단순히 '0'으로 복원하는 방법입니다. 아래 코드에서 위와 같은 preprocessing을 실행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch      Fare  \\\n",
      "0              1         0       3    1  22.0      1      0    7.2500   \n",
      "1              2         1       1    0  38.0      1      0   71.2833   \n",
      "2              3         1       3    0  26.0      0      0    7.9250   \n",
      "3              4         1       1    0  35.0      1      0   53.1000   \n",
      "4              5         0       3    1  35.0      0      0    8.0500   \n",
      "5              6         0       3    1   0.0      0      0    8.4583   \n",
      "6              7         0       1    1  54.0      0      0   51.8625   \n",
      "7              8         0       3    1   2.0      3      1   21.0750   \n",
      "8              9         1       3    0  27.0      0      2   11.1333   \n",
      "9             10         1       2    0  14.0      1      0   30.0708   \n",
      "10            11         1       3    0   4.0      1      1   16.7000   \n",
      "11            12         1       1    0  58.0      0      0   26.5500   \n",
      "12            13         0       3    1  20.0      0      0    8.0500   \n",
      "13            14         0       3    1  39.0      1      5   31.2750   \n",
      "14            15         0       3    0  14.0      0      0    7.8542   \n",
      "15            16         1       2    0  55.0      0      0   16.0000   \n",
      "16            17         0       3    1   2.0      4      1   29.1250   \n",
      "17            18         1       2    1   0.0      0      0   13.0000   \n",
      "18            19         0       3    0  31.0      1      0   18.0000   \n",
      "19            20         1       3    0   0.0      0      0    7.2250   \n",
      "20            21         0       2    1  35.0      0      0   26.0000   \n",
      "21            22         1       2    1  34.0      0      0   13.0000   \n",
      "22            23         1       3    0  15.0      0      0    8.0292   \n",
      "23            24         1       1    1  28.0      0      0   35.5000   \n",
      "24            25         0       3    0   8.0      3      1   21.0750   \n",
      "25            26         1       3    0  38.0      1      5   31.3875   \n",
      "26            27         0       3    1   0.0      0      0    7.2250   \n",
      "27            28         0       1    1  19.0      3      2  263.0000   \n",
      "28            29         1       3    0   0.0      0      0    7.8792   \n",
      "29            30         0       3    1   0.0      0      0    7.8958   \n",
      "..           ...       ...     ...  ...   ...    ...    ...       ...   \n",
      "861          862         0       2    1  21.0      1      0   11.5000   \n",
      "862          863         1       1    0  48.0      0      0   25.9292   \n",
      "863          864         0       3    0   0.0      8      2   69.5500   \n",
      "864          865         0       2    1  24.0      0      0   13.0000   \n",
      "865          866         1       2    0  42.0      0      0   13.0000   \n",
      "866          867         1       2    0  27.0      1      0   13.8583   \n",
      "867          868         0       1    1  31.0      0      0   50.4958   \n",
      "868          869         0       3    1   0.0      0      0    9.5000   \n",
      "869          870         1       3    1   4.0      1      1   11.1333   \n",
      "870          871         0       3    1  26.0      0      0    7.8958   \n",
      "871          872         1       1    0  47.0      1      1   52.5542   \n",
      "872          873         0       1    1  33.0      0      0    5.0000   \n",
      "873          874         0       3    1  47.0      0      0    9.0000   \n",
      "874          875         1       2    0  28.0      1      0   24.0000   \n",
      "875          876         1       3    0  15.0      0      0    7.2250   \n",
      "876          877         0       3    1  20.0      0      0    9.8458   \n",
      "877          878         0       3    1  19.0      0      0    7.8958   \n",
      "878          879         0       3    1   0.0      0      0    7.8958   \n",
      "879          880         1       1    0  56.0      0      1   83.1583   \n",
      "880          881         1       2    0  25.0      0      1   26.0000   \n",
      "881          882         0       3    1  33.0      0      0    7.8958   \n",
      "882          883         0       3    0  22.0      0      0   10.5167   \n",
      "883          884         0       2    1  28.0      0      0   10.5000   \n",
      "884          885         0       3    1  25.0      0      0    7.0500   \n",
      "885          886         0       3    0  39.0      0      5   29.1250   \n",
      "886          887         0       2    1  27.0      0      0   13.0000   \n",
      "887          888         1       1    0  19.0      0      0   30.0000   \n",
      "888          889         0       3    0   0.0      1      2   23.4500   \n",
      "889          890         1       1    1  26.0      0      0   30.0000   \n",
      "890          891         0       3    1  32.0      0      0    7.7500   \n",
      "\n",
      "     Embarked  \n",
      "0         2.0  \n",
      "1         1.0  \n",
      "2         2.0  \n",
      "3         2.0  \n",
      "4         2.0  \n",
      "5         0.0  \n",
      "6         2.0  \n",
      "7         2.0  \n",
      "8         2.0  \n",
      "9         1.0  \n",
      "10        2.0  \n",
      "11        2.0  \n",
      "12        2.0  \n",
      "13        2.0  \n",
      "14        2.0  \n",
      "15        2.0  \n",
      "16        0.0  \n",
      "17        2.0  \n",
      "18        2.0  \n",
      "19        1.0  \n",
      "20        2.0  \n",
      "21        2.0  \n",
      "22        0.0  \n",
      "23        2.0  \n",
      "24        2.0  \n",
      "25        2.0  \n",
      "26        1.0  \n",
      "27        2.0  \n",
      "28        0.0  \n",
      "29        2.0  \n",
      "..        ...  \n",
      "861       2.0  \n",
      "862       2.0  \n",
      "863       2.0  \n",
      "864       2.0  \n",
      "865       2.0  \n",
      "866       1.0  \n",
      "867       2.0  \n",
      "868       2.0  \n",
      "869       2.0  \n",
      "870       2.0  \n",
      "871       2.0  \n",
      "872       2.0  \n",
      "873       2.0  \n",
      "874       1.0  \n",
      "875       1.0  \n",
      "876       2.0  \n",
      "877       2.0  \n",
      "878       2.0  \n",
      "879       1.0  \n",
      "880       2.0  \n",
      "881       2.0  \n",
      "882       2.0  \n",
      "883       2.0  \n",
      "884       2.0  \n",
      "885       0.0  \n",
      "886       2.0  \n",
      "887       2.0  \n",
      "888       2.0  \n",
      "889       1.0  \n",
      "890       0.0  \n",
      "\n",
      "[891 rows x 9 columns]\n",
      "     PassengerId  Pclass  Sex   Age  SibSp  Parch      Fare  Embarked\n",
      "0            892       3    1  34.5      0      0    7.8292         0\n",
      "1            893       3    0  47.0      1      0    7.0000         2\n",
      "2            894       2    1  62.0      0      0    9.6875         0\n",
      "3            895       3    1  27.0      0      0    8.6625         2\n",
      "4            896       3    0  22.0      1      1   12.2875         2\n",
      "5            897       3    1  14.0      0      0    9.2250         2\n",
      "6            898       3    0  30.0      0      0    7.6292         0\n",
      "7            899       2    1  26.0      1      1   29.0000         2\n",
      "8            900       3    0  18.0      0      0    7.2292         1\n",
      "9            901       3    1  21.0      2      0   24.1500         2\n",
      "10           902       3    1   0.0      0      0    7.8958         2\n",
      "11           903       1    1  46.0      0      0   26.0000         2\n",
      "12           904       1    0  23.0      1      0   82.2667         2\n",
      "13           905       2    1  63.0      1      0   26.0000         2\n",
      "14           906       1    0  47.0      1      0   61.1750         2\n",
      "15           907       2    0  24.0      1      0   27.7208         1\n",
      "16           908       2    1  35.0      0      0   12.3500         0\n",
      "17           909       3    1  21.0      0      0    7.2250         1\n",
      "18           910       3    0  27.0      1      0    7.9250         2\n",
      "19           911       3    0  45.0      0      0    7.2250         1\n",
      "20           912       1    1  55.0      1      0   59.4000         1\n",
      "21           913       3    1   9.0      0      1    3.1708         2\n",
      "22           914       1    0   0.0      0      0   31.6833         2\n",
      "23           915       1    1  21.0      0      1   61.3792         1\n",
      "24           916       1    0  48.0      1      3  262.3750         1\n",
      "25           917       3    1  50.0      1      0   14.5000         2\n",
      "26           918       1    0  22.0      0      1   61.9792         1\n",
      "27           919       3    1  22.5      0      0    7.2250         1\n",
      "28           920       1    1  41.0      0      0   30.5000         2\n",
      "29           921       3    1   0.0      2      0   21.6792         1\n",
      "..           ...     ...  ...   ...    ...    ...       ...       ...\n",
      "388         1280       3    1  21.0      0      0    7.7500         0\n",
      "389         1281       3    1   6.0      3      1   21.0750         2\n",
      "390         1282       1    1  23.0      0      0   93.5000         2\n",
      "391         1283       1    0  51.0      0      1   39.4000         2\n",
      "392         1284       3    1  13.0      0      2   20.2500         2\n",
      "393         1285       2    1  47.0      0      0   10.5000         2\n",
      "394         1286       3    1  29.0      3      1   22.0250         2\n",
      "395         1287       1    0  18.0      1      0   60.0000         2\n",
      "396         1288       3    1  24.0      0      0    7.2500         0\n",
      "397         1289       1    0  48.0      1      1   79.2000         1\n",
      "398         1290       3    1  22.0      0      0    7.7750         2\n",
      "399         1291       3    1  31.0      0      0    7.7333         0\n",
      "400         1292       1    0  30.0      0      0  164.8667         2\n",
      "401         1293       2    1  38.0      1      0   21.0000         2\n",
      "402         1294       1    0  22.0      0      1   59.4000         1\n",
      "403         1295       1    1  17.0      0      0   47.1000         2\n",
      "404         1296       1    1  43.0      1      0   27.7208         1\n",
      "405         1297       2    1  20.0      0      0   13.8625         1\n",
      "406         1298       2    1  23.0      1      0   10.5000         2\n",
      "407         1299       1    1  50.0      1      1  211.5000         1\n",
      "408         1300       3    0   0.0      0      0    7.7208         0\n",
      "409         1301       3    0   3.0      1      1   13.7750         2\n",
      "410         1302       3    0   0.0      0      0    7.7500         0\n",
      "411         1303       1    0  37.0      1      0   90.0000         0\n",
      "412         1304       3    0  28.0      0      0    7.7750         2\n",
      "413         1305       3    1   0.0      0      0    8.0500         2\n",
      "414         1306       1    0  39.0      0      0  108.9000         1\n",
      "415         1307       3    1  38.5      0      0    7.2500         2\n",
      "416         1308       3    1   0.0      0      0    8.0500         2\n",
      "417         1309       3    1   0.0      1      1   22.3583         1\n",
      "\n",
      "[418 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 읽어오기\n",
    "preprocessing_train_data = pd.read_csv('data/train.csv')\n",
    "preprocessing_test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "# \"Name\", \"Ticket\", \"Cabin\" 정보 제거\n",
    "preprocessing_train_data.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "preprocessing_test_data.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "# \"Sex\", \"Embarked\" vectorization\n",
    "preprocessing_train_data.replace(['female', 'male'], [0, 1], inplace=True)\n",
    "preprocessing_train_data.replace(['Q', 'C', 'S'], [0, 1, 2], inplace=True)\n",
    "\n",
    "preprocessing_test_data.replace(['female', 'male'], [0, 1], inplace=True)\n",
    "preprocessing_test_data.replace(['Q', 'C', 'S'], [0, 1, 2], inplace=True)\n",
    "\n",
    "# 비워진 데이터 '0'으로 채우기\n",
    "preprocessing_train_data.replace([None], [0], inplace=True)\n",
    "preprocessing_test_data.replace([None], [0], inplace=True)\n",
    "\n",
    "#결과 출력\n",
    "print(preprocessing_train_data)\n",
    "print(preprocessing_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$\\quad$출력을 살펴보면 분석하기 복잡한 정보인 \"Name\", \"Ticket\", \"Cabin\"이 제거되었고, 나머지 정보들 중 숫자정보가 아닌 것들이 제대로 vectorization이 되었음을 확인할 수 있습니다. 그리고 비워져 있던 정보들이 0으로 채워져 preprocessing_data에는 비워진 부분이 하나도 없습니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$위 방법을 통해 간단하게 preprocessing을 해결할 수 있지만 버려지는 데이터가 너무 많아 트레이닝 후 높은 성능을 기대하기 어렵습니다. 그리고 분포에 따른 적절한 preprocessing이 진행되지 않아 과적합(Over-Fitting)문제가 생길 수 있습니다. 따라서 이번에는 위에서 진행했던 데이터 분석을 토대로 진행할 수 있는 몇몇 preprocessing을 소개하고자 합니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$먼저 \"SibSp\", \"Parch\"를 살펴보겠습니다. 앞에서 확인해본 결과 두 정보들은 \"Survived\"와 직접적인 연관성을 가지지는 않으나 약간의 경향성은 가지고 있습니다. 그리고 대부분 탑승객들이 혼자 탑승했거나 동승자가 1명인 경우가 대부분이었습니다. 먼저 이 정보들은 가족이라는 공통점이 있고 경향성이 비슷하므로 두 정보 값을 합한 \"FamilySize\"라는 정보를 새로 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4                           Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  FamilySize  \n",
       "0         A/5 21171   7.2500   NaN        S           1  \n",
       "1          PC 17599  71.2833   C85        C           1  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S           0  \n",
       "3            113803  53.1000  C123        S           1  \n",
       "4            373450   8.0500   NaN        S           0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 읽어오기\n",
    "preprocessing_train_data = pd.read_csv('data/train.csv')\n",
    "preprocessing_test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "# \"SibSp\"와 \"Parch\" 정보를 합쳐 \"FamilySize\" 생성\n",
    "preprocessing_train_data['FamilySize'] = preprocessing_train_data['SibSp'] + preprocessing_train_data['Parch']  \n",
    "preprocessing_test_data['FamilySize'] = preprocessing_test_data['SibSp'] + preprocessing_test_data['Parch'] \n",
    "\n",
    "# \"SibSp\"와 \"Parch\" 제거\n",
    "preprocessing_train_data.drop(['SibSp', 'Parch'], axis=1, inplace=True)\n",
    "preprocessing_test_data.drop(['SibSp', 'Parch'], axis=1, inplace=True)\n",
    "\n",
    "# 결과 상위 5개만 출력\n",
    "preprocessing_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행 결과, \"SibSp\"와 \"Parch\"가 하나의 \"FamilySize\"로 합쳐졌음을 확인할 수 있습니다. 이제 이 데이터가 \"Survived\"와 어떤 관계가 있는지 다음 코드로 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FamilySize</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.303538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.552795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.578431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.724138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Survived\n",
       "FamilySize          \n",
       "7           0.000000\n",
       "10          0.000000\n",
       "5           0.136364\n",
       "4           0.200000\n",
       "0           0.303538\n",
       "6           0.333333\n",
       "1           0.552795\n",
       "2           0.578431\n",
       "3           0.724138"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"FamilySize\"와 \"Survived\" 통계\n",
    "preprocessing_train_data[['FamilySize', 'Survived']].groupby(['FamilySize']).mean().sort_values(by='Survived', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 정보를 합친 결과, 정보 하나를 줄여서 간단하게 만들긴 했으나 아직까지 직접적인 연관성을 얻기는 힘들어보입니다. 따라서 \"FamilySize\"가 4보다 클 경우는 '1', 4보다 작을 경우는 '0'으로 바꿔 정보를 좀 더 간단하게 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4                           Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  FamilySize  \n",
       "0         A/5 21171   7.2500   NaN        S           0  \n",
       "1          PC 17599  71.2833   C85        C           0  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S           0  \n",
       "3            113803  53.1000  C123        S           0  \n",
       "4            373450   8.0500   NaN        S           0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Family size\" 4를 기준으로 하여 0과 1로 구분\n",
    "preprocessing_train_data.loc[preprocessing_train_data['FamilySize'] <= 4, 'FamilySize'] = 0\n",
    "preprocessing_train_data.loc[preprocessing_train_data['FamilySize'] > 4, 'FamilySize'] = 1\n",
    "\n",
    "preprocessing_test_data.loc[preprocessing_test_data['FamilySize'] <= 4, 'FamilySize'] = 0\n",
    "preprocessing_test_data.loc[preprocessing_test_data['FamilySize'] > 4, 'FamilySize'] = 1\n",
    "\n",
    "# 결과 상위 5개 출력\n",
    "preprocessing_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FamilySize</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.396919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.148936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Survived\n",
       "FamilySize          \n",
       "0           0.396919\n",
       "1           0.148936"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"FamilySize\"와 \"Survived\" 통계\n",
    "preprocessing_train_data[['FamilySize', 'Survived']].groupby(['FamilySize']).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과, \"FamilySize\"와 \"Survived\"사이에 직접적 연관성을 얻을 수 있었습니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$\"Sex\"와 \"Embarked\"는 \"Survived\"를 판단하는데 직접적인 영향을 주는 정보임을 앞에서 확인할 수 있었습니다. 따라서 이 두 정보는 별 다른 preprocessing이 필요하지 않고 단순히 손실된 부분을 복원하고 vectorization만 실행시켜주면 됩니다. \n",
    "<br>\n",
    "<br>\n",
    "$\\quad$먼저 \"Embarked\"의 손실된 데이터를 복원하겠습니다. 데이터 분석에서 확인했등시 \"Embarked\"는 전체 탑승객 중 2명의 정보가 알려져 있지 않습니다. 따라서 이 2명의 정보를 복원시켜줘야 합니다. 본 preproessing에서는 2명의 \"Embakred\"정보를 가장 많은 탑승객이 이용했던 'S' 승강장으로 지정하고자 합니다. 손실된 데이터를 복원한 후 \"Sex\"의 'female', 'male'을 '0', '1'로 지정시키고 \"Embarked\"의 'Q', 'C', 'S'를 '0', '1', '2'로 지정하여 vectorization을 해줍니다. 아래 코드에서 이 과정을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  Embarked\n",
       "0    1         2\n",
       "1    0         1\n",
       "2    0         2\n",
       "3    0         2\n",
       "4    1         2"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Embarked\" 빈 정보 S로 채우기\n",
    "preprocessing_train_data['Embarked'].replace([None], ['S'], inplace=True)\n",
    "preprocessing_test_data['Embarked'].replace([None], ['S'], inplace=True)\n",
    "\n",
    "# \"Embarked\", \"Sex\" vectorization\n",
    "preprocessing_train_data.replace(['female', 'male'], [0, 1], inplace=True)\n",
    "preprocessing_train_data.replace(['Q', 'C', 'S'], [0, 1, 2], inplace=True)\n",
    "\n",
    "preprocessing_test_data.replace(['female', 'male'], [0, 1], inplace=True)\n",
    "preprocessing_test_data.replace(['Q', 'C', 'S'], [0, 1, 2], inplace=True)\n",
    "\n",
    "# 결과 상위 5개 출력\n",
    "preprocessing_train_data[['Sex', 'Embarked']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 결과 위와 같이 잘 수행되었음을 확인할 수 있습니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$\"Name\", \"Ticket\", \"Cabin\"은 복잡한 데이터로 \"Survived\"와 직접적인 연관성을 찾아내기 어렵습니다. 따라서 대부분의 경우 이 세 정보는 제거하고 사용하게 됩니다. 다만, 정보를 제거하게 되면 그 정보에서 얻을 수 있는 일부 정보까지도 잃게 되므로 학습할 때 정확성이 떨어지게 됩니다. 본 preprocessing에서는 \"Name\"의 정보 중 의미 있는 정보를 추출하여 새로운 정보를 생성하는 과정을 설명하고자 합니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$\"Name\"을 살펴보면 중간에 쉼표와 온점 사이에 'Mr', 'Mrs', 'Capt', 'Master' 등 그 사람의 직위나 결혼 여부를 확인할 수 있는 정보가 담겨있습니다. \"Name\" 속의 이러한 정보를 추출하여 새로운 정보인 \"Title\"을 생성해보겠습니다. 추출 이후에는 \"Title\", \"Ticket\", \"Cabin\"정보를 제거하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countess</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex         0    1\n",
       "Title             \n",
       "Capt        0    1\n",
       "Col         0    2\n",
       "Countess    1    0\n",
       "Don         0    1\n",
       "Dr          1    6\n",
       "Jonkheer    0    1\n",
       "Lady        1    0\n",
       "Major       0    2\n",
       "Master      0   40\n",
       "Miss      182    0\n",
       "Mlle        2    0\n",
       "Mme         1    0\n",
       "Mr          0  517\n",
       "Mrs       125    0\n",
       "Ms          1    0\n",
       "Rev         0    6\n",
       "Sir         0    1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Name\" 중 일부 추출하여 \"Title\" 생성\n",
    "preprocessing_train_data['Title'] = preprocessing_train_data.Name.str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "preprocessing_test_data['Title'] = preprocessing_test_data.Name.str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# \"Name\", \"Ticket\", \"Cabin\" 제거\n",
    "preprocessing_train_data.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "preprocessing_test_data.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "# \"Title\" 정보 통계\n",
    "pd.crosstab(preprocessing_train_data['Title'], preprocessing_train_data['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과를 살펴보면 'Master', 'Mr', 'Mrs', 'Ms' 이외의 \"Title\"을 가지고 있는 승객은 극소수임을 확인할 수 있습니다. 따라서 이러한 \"Title\"은 Rare라는 \"Title\"로 대체하고자 합니다.. 그리고 'Ms', 'Mlle', 'Mme'는 모두 'Miss'이므로 'Miss'로 대체합니다. 대체한 이후 'Mr'는 '1', 'Miss'는 '2', 'Mrs'는 '3', 'Master'는 '4', 'Rare'는 '5'로 vectorization 해주고 \"Title\"이 없는 경우는 '0'으로 지정하고자 합니다. 이 과정은 아래 코드에서 실행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex   Age     Fare  Embarked  FamilySize  \\\n",
       "0            1         0       3    1  22.0   7.2500         2           0   \n",
       "1            2         1       1    0  38.0  71.2833         1           0   \n",
       "2            3         1       3    0  26.0   7.9250         2           0   \n",
       "3            4         1       1    0  35.0  53.1000         2           0   \n",
       "4            5         0       3    1  35.0   8.0500         2           0   \n",
       "\n",
       "   Title  \n",
       "0      1  \n",
       "1      3  \n",
       "2      2  \n",
       "3      3  \n",
       "4      1  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주요 \"Title\"을 제외한 나머지는 'Rare'로 분류\n",
    "preprocessing_train_data['Title'].replace(['Lady', 'Countess', 'Capt','Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare', inplace=True)  \n",
    "preprocessing_test_data['Title'].replace(['Lady', 'Countess', 'Capt','Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare', inplace=True) \n",
    "\n",
    "# 'Ms', 'Mlle', 'Mme'를 'Miss'로 통일\n",
    "preprocessing_train_data['Title'].replace(['Ms', 'Mlle', 'Mme'], ['Miss', 'Miss', 'Miss'], inplace=True)\n",
    "preprocessing_test_data['Title'].replace(['Ms', 'Mlle', 'Mme'], ['Miss', 'Miss', 'Miss'], inplace=True)\n",
    "\n",
    "# \"Title\" vectorization\n",
    "preprocessing_train_data['Title'].replace(['Mr', 'Miss', 'Mrs', 'Master', 'Rare'], [1, 2, 3, 4, 5], inplace=True)\n",
    "preprocessing_test_data['Title'].replace(['Mr', 'Miss', 'Mrs', 'Master', 'Rare'], [1, 2, 3, 4, 5], inplace=True)\n",
    "\n",
    "# \"Title\"이 없는 데이터는 '0'으로 지정\n",
    "preprocessing_train_data['Title'].replace([None], [0], inplace=True)\n",
    "preprocessing_test_data['Title'].replace([None], [0], inplace=True)\n",
    "\n",
    "# 결과 상위 5개 출력\n",
    "preprocessing_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$아직까지 preprocessing을 거치지 않은 정보는 \"Age\"와 \"Fare\"입니다. 이 두 정보는 연속적인 숫자 데이터로서 그대로 사용하게 되면 학습효과가 떨어지게 됩니다. 예를 들어 training 데이터의 \"Age\"정보에 38과 44 사이의 값을 가지는 경우가 하나도 없다고 가정해보겠습니다. 이 때 test데이터의 \"Age\"정보 중 41, 42처럼 38과 44 사이의 값을 가지는 정보는 충분히 training 되지 않았으므로 생존여부 판단에 큰 도움이 되지 못합니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$이러한 문제는 구간을 나누어 특정 값으로 매칭시켜주는 방법으로 해결할 수 있습니다. 예를 들어 \"Age\" 정보를 10대, 20대, 30대, 40대 등으로 나누어 새로운 \"AgeBnad\"라는 정보를 생성하는 방법이 있습니다. 이러한 preprocessing 과정은 \"FamilySize\"를 생성하는 과정과 유사하므로 생략하도록 하겠습니다. (직접 구현)\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$\"Age\"의 경우 손실된 부분이 존재하므로 이를 복원하는 과정이 필요합니다. 본 preprocessing에서는 비워진 부분을 나머지 탑승객의 평균으로 지정하도록 할 것입니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$위에서 말한 내용들은 아래 코드로 구현되어 있습니다. (\"Age\", \"Fare\"를 특정 구간으로 나누어 값을 바꾸는 과정은 생략하였습니다. 위 가이드를 참고하여 직접 해보시길 바랍니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 비워진 부분을 평균 나이로 복원\n",
    "preprocessing_train_data['Age'].replace([None], [30], inplace=True)  \n",
    "preprocessing_test_data['Age'].replace([None], [30], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex   Age     Fare  Embarked  FamilySize  \\\n",
       "0            1         0       3    1  22.0   7.2500         2           0   \n",
       "1            2         1       1    0  38.0  71.2833         1           0   \n",
       "2            3         1       3    0  26.0   7.9250         2           0   \n",
       "3            4         1       1    0  35.0  53.1000         2           0   \n",
       "4            5         0       3    1  35.0   8.0500         2           0   \n",
       "\n",
       "   Title  \n",
       "0      1  \n",
       "1      3  \n",
       "2      2  \n",
       "3      3  \n",
       "4      1  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 출력\n",
    "preprocessing_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 제시한 모든 preprocessing을 거친 결과는 위와 같습니다. \"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\" 총 7가지 정보와 \"Survived\"가 담겨져 있으며 모두 적당히 \"Survived\"와 연관성을 가지도록 class가 나누어지고, 비워진 부분들이 복원되었음을 확인할 수 있습니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning\n",
    "$\\quad$이제 preprocessing을 거친 데이터를 이용하여 machine learning 알고리즘을 적용시켜볼 것입니다. 본 프로젝트에서는 오전 강의 때 리뷰했던 'KNN', 'Logistic Regression', 'SVM', 'DecisionTree', 'RandomForest'를 사용할 것입니다.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$각 알고리즘을 사용하기 위해 preprocessing을 거친 데이터에서 \"Survived\"와 의미없는 \"PassangerId\"를 제거하여 training 데이터를 만들고, \"Survived\"만 추출하여 label 데이터를 만듭니다. (test데이터에서도 \"PassagerId\" 제거) 그리고 각 알고리즘들을 적용시키고, 그 결과로 만들어진 모델로 test데이터를 예측하여 파일로 저장하여 kaggle에 제출합니다. 코드는 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training을 위한 데이터 생성\n",
    "X_train = preprocessing_train_data.drop(['Survived', 'PassengerId'], axis=1)\n",
    "Y_train = preprocessing_train_data[\"Survived\"]\n",
    "X_test = preprocessing_test_data.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  80.36\n",
      "Area Under the Curve:  0.87\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 알고리즘 선택, 사용하고 싶은 알고리즘을 classifier로 지정하여 사용\n",
    "# classifier = KNeighborsClassifier()\n",
    "classifier = LogisticRegression()\n",
    "# classifier = SVC(probability=True)\n",
    "# classifier = DecisionTreeClassifier()\n",
    "# classifier = RandomForestClassifier()\n",
    "# classifier = GaussianNB()\n",
    "\n",
    "# 위에서 설정한 classifier의 accuracy 및 AUC, ROC 곡선 확인\n",
    "classifier.fit(X_train, Y_train)\n",
    "accuracy = classifier.score(X_train, Y_train) * 100\n",
    "Y_train_pred = classifier.predict_proba(X_train)[:, 1]\n",
    "\n",
    "FPR, TPR, thresholds = roc_curve(Y_train, Y_train_pred)\n",
    "AUC = roc_auc_score(Y_train, Y_train_pred)\n",
    "\n",
    "plt.plot(FPR, TPR)\n",
    "print(\"Accuracy: \", \"{0:.2f}\".format(accuracy))\n",
    "print(\"Area Under the Curve: \", \"{0:.2f}\".format(AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터 예측 결과 출력 및 kaggle 제출파일 생성\n",
    "predict = classifier.predict(X_test)\n",
    "predict = np.round(predict)\n",
    "\n",
    "# kaggle 제출 파일 생성\n",
    "submission = pd.DataFrame({'PassengerId': preprocessing_test_data['PassengerId'], 'Survived': predict})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
